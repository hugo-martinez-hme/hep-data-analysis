# High Energy Physics & AI Engineering Research

I am an Artificial Intelligence student at the Universidade de Vigo (UVigo). This repository serves as a personal laboratory for exploring the intersection of High-Performance Computing (HPC), Machine Learning, and particle physics.

My research focuses on the computational challenges of the Large Hadron Collider (LHC) at CERN, specifically regarding algorithmic optimization and deterministic AI.

## Technical Focus

* **Data Systems:** Implementing columnar analysis using the Scikit-HEP ecosystem (UpROOT, Awkward Array) to optimize I/O and memory efficiency.
* **Physics-Informed ML:** Moving beyond "black-box" models by integrating physical constraints (relativistic kinematics and energy conservation) into neural architectures.
* **Systems Engineering:** Developing on Arch Linux while ensuring reproducibility through AlmaLinux 9 containers, following CERN production standards.

## Project Structure

* **`01_Foundations/`**: Mathematical modeling and core physics concepts (Special Relativity, Electromagnetism) alongside HSF software standards.
* **`02_ATLAS_TileCal/`**: Energy reconstruction research. Development of CNNs for signal processing and amplitude recovery in high-noise calorimeter environments.
* **`03_CMS_Archi/`**: Engineering "Agentic" workflows. Implementation of the Model Context Protocol (MCP) for reliable AI assistants in computing operations.
* **`04_Data_Sandbox/`**: Local environment for raw dataset processing (ignored by version control).

## Infrastructure & Standards

* **OS:** Arch Linux (Development) / AlmaLinux 9 (Target/Docker).
* **CI/CD:** Automated testing via GitHub Actions.
* **Version Control:** Strictly following the Conventional Commits specification.
