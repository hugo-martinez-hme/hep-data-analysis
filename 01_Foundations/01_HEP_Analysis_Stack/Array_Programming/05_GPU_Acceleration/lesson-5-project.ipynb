{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e39776f-07e4-4674-94f2-7b652ef3e7c3",
   "metadata": {},
   "source": [
    "# Lesson 5 project: Histograms and Monte Carlo on GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c6264-b8be-462b-adbb-d4cb2d60d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import numba as nb\n",
    "import numba.cuda\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "from hist import Hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa2e35-da4f-45e1-ac0a-c99bfe309cc9",
   "metadata": {},
   "source": [
    "The three exercises below are independent: you can start with whichever one you want.\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fca08-6c5b-4886-ba53-063bf738a12f",
   "metadata": {},
   "source": [
    "## Exercise 1: make a CUDA kernel with Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695bf69-f8ce-4aba-85de-48c853d02397",
   "metadata": {},
   "source": [
    "We'll use the non-ragged data from [lesson-2-project.ipynb](lesson-2-project.ipynb) by casting each array from an HDF5 file as CuPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756114ee-0028-4a36-9cd7-269ead9bcff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hdf5 = h5py.File(\"data/SMHiggsToZZTo4L.h5\")\n",
    "e1_pt = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e1\"][\"pt\"])\n",
    "e1_phi = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e1\"][\"phi\"])\n",
    "e1_eta = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e1\"][\"eta\"])\n",
    "e2_pt = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e2\"][\"pt\"])\n",
    "e2_phi = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e2\"][\"phi\"])\n",
    "e2_eta = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e2\"][\"eta\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533554c4-fbe0-4d28-aafd-312969301fdf",
   "metadata": {},
   "source": [
    "We can use CuPy's array interface to compute the mass with\n",
    "\n",
    "$$\\sqrt{2\\,{p_T}_1\\,{p_T}_2\\left(\\cosh(\\eta_1 - \\eta_2) - \\cos(\\phi_1 - \\phi_2)\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf4d0f-0302-4bf3-bf2a-d37763d92a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mass = cp.sqrt(\n",
    "    2*e1_pt*e2_pt * (cp.cosh(e1_eta - e2_eta) - cp.cos(e1_phi - e2_phi))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12734ce1-6f79-43c8-8842-caa9bb8ca18d",
   "metadata": {},
   "source": [
    "To plot it, we have to copy the result from GPU to RAM with `z_mass.get()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184d1fd0-2f75-43f7-acf5-3079f01f57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "Hist.new.Reg(120, 0, 120, name=\"e+e- mass (GeV)\").Double().fill(z_mass.get()).plot()\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e0b3c-ea20-43fe-bd0f-8b31fb188f7b",
   "metadata": {},
   "source": [
    "Now fuse the operations from that formula into a single kernel with Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50ef2d-4de7-4441-8a0d-5d219aa7d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def compute_z_mass(e1_pt, e1_phi, e1_eta, e2_pt, e2_phi, e2_eta, z_mass):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8d3e7-3a0e-45d6-a727-508f246da4f1",
   "metadata": {},
   "source": [
    "You'll also need to calculate an optimal `threads_per_block` and `blocks_per_grid` to call it. Make the same plot as above.\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f7b9b-6e7f-47a4-8be6-7638b1e901eb",
   "metadata": {},
   "source": [
    "## Exercise 2: fill a histogram on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d4a35-364e-4db3-90e6-524272d6332c",
   "metadata": {},
   "source": [
    "This time, you'll fill the histogram on the GPU and only copy the filled bin contents from GPU to RAM.\n",
    "\n",
    "The dataset is larger, 10 million dimuon masses. Pretend that the histogram code you're writing will be applied to data that was computed on the GPU, to avoid a costly data transfer before reducing it to a small set of bin contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b93c0-00ff-4c18-8f20-137dacd48122",
   "metadata": {},
   "outputs": [],
   "source": [
    "with uproot.open(\"data/dimuon_mass.root:tree/mass\") as branch:\n",
    "    dimuon_mass = cp.asarray(branch.array(library=\"np\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c0021-61c1-4d1c-b934-371475f2f663",
   "metadata": {},
   "source": [
    "The histogram will have 1200 bins and cover a range from 0 to 120 GeV, with the overflows going in the nearest edge bin. Thus, the mass-to-bin calculation is simple:\n",
    "\n",
    "```python\n",
    "bin_index = int(mass * 10)\n",
    "if bin_index < 0:\n",
    "    bin_index = 0\n",
    "elif bin_index >= 1200:\n",
    "    bin_index = 1199\n",
    "```\n",
    "\n",
    "and the plot should look like\n",
    "\n",
    "![](img/lesson-5-exercise-2-expectation.png)\n",
    "\n",
    "The histogram bins is another array that you'll pass to the Numba-based kernel function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a35f3-6280-4e96-b7d2-44fd6ab50d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_values = cp.zeros(1200, dtype=cp.uint32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52221b-6b2a-4f15-a988-15ee7415cb33",
   "metadata": {},
   "source": [
    "You might be tempted to fill the histogram with\n",
    "\n",
    "```python\n",
    "bin_values[bin_index] += 1\n",
    "```\n",
    "\n",
    "but you'll find that it doesn't reproduce the plot above. (Try it!)\n",
    "\n",
    "The problem is that multiple threads might try to fill the same bin at the same time.\n",
    "\n",
    "| thread 1 | thread 2 |\n",
    "|:--:|:--:|\n",
    "| reads `bin_value[123]`; it's 5 | |\n",
    "| | reads `bin_value[123]`; it's 5 |\n",
    "| increments the value to 6 | |\n",
    "| | increments the value to 6 |\n",
    "| write 6 to `bin_value[123]` |\n",
    "| | writes 6 to `bin_value[123]` |\n",
    "\n",
    "but since both threads wanted to increment `bin_value[123]`, it ought to be 7. This is a \"race condition\" (both threads are racing to change the value), and it can affect any parallel processing code, GPU code included.\n",
    "\n",
    "One way to solve race conditions is to make the output \"atomic\". In an atomic counter, the three steps in\n",
    "\n",
    "1. read current value\n",
    "2. increment it\n",
    "3. write the incremented value\n",
    "\n",
    "are one atomic operation (in the sense of \"atomic\" meaning \"unbreakable\"): thread 2 can't start the operation until thread 1 is done.\n",
    "\n",
    "CUDA supplies some atomic operations and Numba makes them available as `nb.cuda.atomic.*` ([see documentation](https://numba.readthedocs.io/en/stable/cuda/intrinsics.html)). Which one(s) would be useful here?\n",
    "\n",
    "Note that atomic operations are only defined for a limited set of numeric data types (`dtype`). If you need to define `bin_values` as an unsigned integer, go ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d79e6-e109-46ee-8abe-75c1a3ee346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def fill_histogram(bin_values, dimuon_mass):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    if thread_idx < len(dimuon_mass):\n",
    "        ...\n",
    "\n",
    "threads_per_block = ...\n",
    "blocks_per_grid = ...\n",
    "\n",
    "fill_histogram[blocks_per_grid, threads_per_block](bin_values, dimuon_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d7a88-d346-4372-97d6-1e85193b33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "h = Hist.new.Reg(1200, 0, 120, label=\"dimuon mass (GeV)\").Double()\n",
    "h.values()[:] = bin_values.get()\n",
    "h.plot(ax=ax)\n",
    "\n",
    "ax.set_xlim(0, 120)\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e961e-ae44-4ea3-8036-4bf3abf85443",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f3210-f1bb-4f90-92ec-7d7055a9d9d6",
   "metadata": {},
   "source": [
    "## Exercise 3: use Monte Carlo to calculate π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a03dd6b-150b-467e-9570-195b0ad47ced",
   "metadata": {},
   "source": [
    "All of the examples we've seen so far use the GPU to analyze data. What if you want to generate Monte Carlo samples?\n",
    "\n",
    "Random numbers need to be used carefully with parallel processing, since it's easy to accidentally generate the same (or correlated) random numbers on different processors, which invalidates the result in hard-to-discover ways. This is because \"random numbers\" really means \"arbitrary numbers\", since a GPU, like any other computational device, is deterministic. A sequence of \"random numbers\" is a sequence that would be unsurprising if we were expecting a uniformly distributed, statistically independent set.\n",
    "\n",
    "For instance, if we copied a NumPy random number generator to two processes running in parallel,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc038cc-7c5b-4be7-8c4f-2f20f93b4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng1 = np.random.default_rng()\n",
    "rng2 = copy.deepcopy(rng1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc31c0e-3e8f-4b11-ad79-06f874a4188f",
   "metadata": {},
   "source": [
    "both processes would generate the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418d011-f8c1-4a0b-b6ec-02431d9601d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng1.integers(0, 100, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5acab-b187-44bd-a1d0-8914f209d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng2.integers(0, 100, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002268b5-2f49-4b77-97b0-fda791937c0c",
   "metadata": {},
   "source": [
    "To prevent this, [np.random.Generator](https://numpy.org/doc/stable/reference/random/generator.html) has a [spawn](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.spawn.html) method, which makes a set of generators that are guaranteed independent and uncorrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a966a-45c1-4312-9f62-42c9733a4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "rng1, rng2 = rng.spawn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71907538-aed2-43d7-9679-676608807ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng1.integers(0, 100, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef5b37-4a05-4e03-8799-1e3ac0559408",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng2.integers(0, 100, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086cad85-3d16-45a4-b39c-36a0e4eb4ac9",
   "metadata": {},
   "source": [
    "(The correlation coefficient is about 0.001 for off-diagonal elements in a set of a million Gaussian-distributed values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00165e-323a-4d20-b75c-8f907daf3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(rng1.normal(0, 1, 1000000), rng2.normal(0, 1, 1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b6626-34bb-425a-81c6-7a3d72e892cb",
   "metadata": {},
   "source": [
    "For a GPU kernel, we need to spawn as many random number generators as we have threads. For a massively parallel process, that can be a lot of seeds!\n",
    "\n",
    "In Numba, the functions that spawn and use these generators are called `nb.cuda.random.*xoroshiro128p*` ([see documentation](https://numba.readthedocs.io/en/stable/cuda/random.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf97866-b0e6-4100-a6bf-1a31bdaa57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.cuda.random import create_xoroshiro128p_states\n",
    "from numba.cuda.random import xoroshiro128p_uniform_float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9545e-1dfa-44c8-83e1-4c6091e70998",
   "metadata": {},
   "source": [
    "This generates 10000 generators (outside of the kernel) and then runs each generator for 1000 steps (inside the kernel) to get 10000 × 1000 random floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c3bcd-c600-4222-90ba-f8ec64fb3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def generate_uniform(rng_states, out):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    for j in range(1000):\n",
    "        out[thread_idx, j] = xoroshiro128p_uniform_float32(rng_states, thread_idx)\n",
    "\n",
    "out = cp.empty((10000, 1000), dtype=np.float32)\n",
    "\n",
    "threads_per_block = 1024\n",
    "blocks_per_grid = int(np.ceil(len(out) / 1024))\n",
    "\n",
    "rng_states = create_xoroshiro128p_states(threads_per_block * blocks_per_grid, seed=12345)\n",
    "\n",
    "generate_uniform[blocks_per_grid, threads_per_block](rng_states, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfac7de-d905-41e6-a6f1-5cfec4381f04",
   "metadata": {},
   "source": [
    "For performance, there's a balance between having enough blocks to keep the whole GPU busy and having to spawn such a large number of generators (outside the kernel) that the spawning process takes more time than the GPU kernel.\n",
    "\n",
    "In this exercise, you need to sample random number pairs $x \\in (-1, 1)$, $y \\in (-1, 1)$ with a uniform distribution to compute the area of a circle with radius $r = 1$. Then use the area $A = \\pi r^2$ formula to derive $\\pi$.\n",
    "\n",
    "* How does the accuracy depend on number of sampled pairs?\n",
    "* What about the computation time?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
